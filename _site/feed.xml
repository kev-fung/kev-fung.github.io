<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-09-23T12:44:02+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">kkyfung</title><subtitle></subtitle><entry><title type="html">When Machine Learning Models Break: A Lesson in Numerical Instability [Regression] [Machine Learning]</title><link href="http://localhost:4000/jekyll/update/2024/09/12/exploding-infinities.html" rel="alternate" type="text/html" title="When Machine Learning Models Break: A Lesson in Numerical Instability [Regression] [Machine Learning]" /><published>2024-09-12T08:53:16+01:00</published><updated>2024-09-12T08:53:16+01:00</updated><id>http://localhost:4000/jekyll/update/2024/09/12/exploding-infinities</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/09/12/exploding-infinities.html"><![CDATA[<p>In large-scale machine learning platforms with simplified workflows, model implementations can become black boxes. I once worked on such a platform where linear regression models started producing weights in the magnitude of 10^12 figures, leading to infinities after applying np.exp(). The only change I made was the EC2 instance type!</p>

<h6 id="diving-into-the-cause">Diving into the cause</h6>

<p>Initially I thought it was a difference in how random seeds defaulted based on the internal implementation we used for regression. Fixing it did not work. So I injected logs throughout the system, trying to understand the data at every step of the flow - perhaps the data IO step corrupted the model inputs or there was a division of zero happening due to numerical precision? Only at the modelling step I discovered the models had extremely high condition numbers!</p>

<p>The workflow was using an internal component that transformed the dataset to keep only a large group of one hot encoded features to predict the target labels. The result was a highly sparse, massive columnar dataset with many duplicated rows (and each with a different label!). The models were solved via OLS, where its implementation calculated the pseudo-inverse of the matrix - thus it was attempting to solve an extremely ill-conditioned matrix and this was naturally producing numerical instability down to the machine level precision in its calculations!</p>

<p>The objective of the workflow was to predict the weights for every combination of categorical variables, rather than the label data - this was effectively an inverse problem we were trying to solve.</p>

<h6 id="controlling-the-explosion">Controlling the explosion</h6>

<p>There were several practical solutions to tackle this issue. One approach was to properly containerise the application, which would ensure consistency across different machine types, as long as the platform‚Äôs scale and complexity allowed for it. Since we were using OLS, switching to an iterative solver like SGD could have resolved the exploding values. While this might have impacted the model‚Äôs perceived performance and increased convergence time, it would at least have provided more stability.</p>

<p>Another option was to apply regularization by introducing a bias term to stabilize the solver. Techniques like L1 or L2 regularization could have helped, although they would have sacrificed some precision in the model weights. Accuracy was crucial for our specific use case, so this trade-off required careful consideration along with Machine Learning Scientists.</p>

<p>What you should realise by now is that despite the possible mathematical and computational solutions to remove the infinities, the wiser decision was to reconsider the existing methodology. The business problem the workflow was constrained to was definitely a hard problem to solve - however this experience has reminded me the importance of taking into consideration numerical stability (and fundamentally how numerical models are solved) when building machine learning solutions and it should be part of any ML practioners toolkit.</p>

<p><br /></p>

<p>// Kudos to John and Debs when we watched F1 in the pub üèéÔ∏è</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[In large-scale machine learning platforms with simplified workflows, model implementations can become black boxes. I once worked on such a platform where linear regression models started producing weights in the magnitude of 10^12 figures, leading to infinities after applying np.exp(). The only change I made was the EC2 instance type!]]></summary></entry><entry><title type="html">Understanding Binary Search [Problem Solving]</title><link href="http://localhost:4000/jekyll/update/2024/06/08/binarysearch-beauty.html" rel="alternate" type="text/html" title="Understanding Binary Search [Problem Solving]" /><published>2024-06-08T08:53:16+01:00</published><updated>2024-06-08T08:53:16+01:00</updated><id>http://localhost:4000/jekyll/update/2024/06/08/binarysearch-beauty</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/06/08/binarysearch-beauty.html"><![CDATA[<p>Binary search is as the name implies, it searches for something by splitting and only considering either the left or right halves of an array. Should be simple, but can be confusing so - how do we properly understand this?</p>

<p>In short:</p>

<p>Binary search finds the MINIMUM value that satisfies the condition you provide it.</p>

<p>Why?</p>

<p>The classic binary search problem where it asks to find a value in a sorted array is one of the biggest pitfalls into thinking that the implementation must separate the search into three part, the left, the middle, and the right part. This is the WRONG THINKING for binary search, and it does not generalise to harder problems requiring binary search.</p>

<p>The generalised implementation of binary search only needs to split the search into two parts, the left and the right - because binary search only considers a binary condition - true or false. Depending on which, we will traverse down either left or right parts. This is obvious.</p>

<p>The crux of the issue comes however, when we ask ourselves, how do we return the value we want? If we only consider left and right parts how do we also include the middle part (the value which we check)? The simple implementation would have just returned the middle part, but this time we only have the left and right parts.</p>

<p>This is when we must determine if we should include the middle part as always the ‚Äúleft part‚Äù or the ‚Äúright part‚Äù.</p>

<p>Imagine a problem to find the first ‚ÄúX‚Äù in this array of X and O.</p>

<p><strong>OOOOOXXXXXXX</strong></p>

<p>Now say we run our binary search and eventually we reach some point where we‚Äôre only considering the subarray:</p>

<p><strong>OXXXX</strong></p>

<p>If we look at this, our current midpoint is X (which is also the global answer to our example problem - but not the first X in this subarray of X‚Äôs!) and we should see that because we‚Äôre in the middle of the right part, we can do better and keep looking to the left of this current search, and as we search through these X‚Äôs one of these visited X‚Äôs must be the final answer! Therefore it obvious to consider our target/midway-value to be in the right half always. This is why we next: 1) look at the left part 2) include this midway-value for our search.</p>

<p>We‚Äôll always look to search like this OX, OOX, OOOX, OOOOX, OOOOOX.</p>

<p>Now we realise this, our implementation will look something like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>If condition==True:
    update right pointer to equal to mid-way point. 
    # (i.e. only consider our left part + midway value now).
Else:
    update left pointer to equal mid-way point + 1. 
    # (i.e. only consider our right part exc. midway value now). 
</code></pre></div></div>

<p>Conversely another insight here is when condition==False, our midpoint is currently in the OOO part, and we obviously don‚Äôt want to include this current midpoint in our search. Thus we exclude it from our next search by shifting left pointer to midpoint + 1.</p>

<p>When the target value doesn‚Äôt exist, this algorithm will just return the next best value that meet‚Äôs the condition.</p>

<p>Why does searching for values in sorted array work with binary search?</p>

<p>We just need to reframe the problem. In reality, if we apply this notion of some binary domain to our problem (e.g. OOOOXXXXXs), we‚Äôre basically saying:</p>

<p>Let‚Äôs split our array into numbers smaller than the number of our interest, and numbers larger or equal to the number of our interest.</p>

<p>e.g. I want to find 4 in 1234567:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1 2 3 4 5 6 7
OOO X X X X
</code></pre></div></div>

<p>So our solution to this problem boils back to what we‚Äôve just described.</p>

<!-- You‚Äôll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run `jekyll serve`, which launches a web server and auto-regenerates your site when a file is updated. This is another one!


Jekyll requires blog post files to be named according to the following format:

`YEAR-MONTH-DAY-title.MARKUP`

Where `YEAR` is a four-digit number, `MONTH` and `DAY` are both two-digit numbers, and `MARKUP` is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.

Jekyll also offers powerful support for code snippets:


<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>


Check out the [Jekyll docs][jekyll-docs] for more info on how to get the most out of Jekyll. File all bugs/feature requests at [Jekyll‚Äôs GitHub repo][jekyll-gh]. If you have questions, you can ask them on [Jekyll Talk][jekyll-talk].

[jekyll-docs]: https://jekyllrb.com/docs/home
[jekyll-gh]:   https://github.com/jekyll/jekyll
[jekyll-talk]: https://talk.jekyllrb.com/ -->]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Binary search is as the name implies, it searches for something by splitting and only considering either the left or right halves of an array. Should be simple, but can be confusing so - how do we properly understand this?]]></summary></entry></feed>